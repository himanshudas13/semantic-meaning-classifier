{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 1423,
          "sourceType": "datasetVersion",
          "datasetId": 747
        },
        {
          "sourceId": 8240,
          "sourceType": "datasetVersion",
          "datasetId": 5504
        },
        {
          "sourceId": 245687,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 209925,
          "modelId": 231619
        }
      ],
      "dockerImageVersionId": 30839,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Quora-semantic",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/himanshudas13/semantic-meaning-classifier/blob/main/Quora_semantic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "organizations_quora_question_pairs_dataset_path = kagglehub.dataset_download('organizations/quora/question-pairs-dataset')\n",
        "thanakomsn_glove6b300dtxt_path = kagglehub.dataset_download('thanakomsn/glove6b300dtxt')\n",
        "numberninja13_semantic_similarity_keras_default_1_path = kagglehub.model_download('numberninja13/semantic-similarity/Keras/default/1')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "q7RC0lT8xnhS"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T09:05:04.285443Z",
          "iopub.execute_input": "2025-01-30T09:05:04.285798Z",
          "iopub.status.idle": "2025-01-30T09:05:05.274601Z",
          "shell.execute_reply.started": "2025-01-30T09:05:04.28577Z",
          "shell.execute_reply": "2025-01-30T09:05:05.273838Z"
        },
        "id": "laNPBYuOxnhV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install  nltk\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T09:05:05.275888Z",
          "iopub.execute_input": "2025-01-30T09:05:05.276602Z",
          "iopub.status.idle": "2025-01-30T09:05:10.656838Z",
          "shell.execute_reply.started": "2025-01-30T09:05:05.276556Z",
          "shell.execute_reply": "2025-01-30T09:05:10.655843Z"
        },
        "id": "iHGucaUxxnhV",
        "outputId": "ffe94a23-3fc9-4224-8cd7-b1a1b572289d"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.2.4)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from nltk) (1.17.0)\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
          "output_type": "stream"
        },
        {
          "execution_count": 4,
          "output_type": "execute_result",
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "STOP_WORDS = stopwords.words(\"english\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T09:05:10.658867Z",
          "iopub.execute_input": "2025-01-30T09:05:10.659138Z",
          "iopub.status.idle": "2025-01-30T09:05:10.665593Z",
          "shell.execute_reply.started": "2025-01-30T09:05:10.659114Z",
          "shell.execute_reply": "2025-01-30T09:05:10.664683Z"
        },
        "id": "_yBm4HwqxnhW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/kaggle/input/question-pairs-dataset/questions.csv')\n",
        "df.shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T09:05:10.667109Z",
          "iopub.execute_input": "2025-01-30T09:05:10.667395Z",
          "iopub.status.idle": "2025-01-30T09:05:12.334664Z",
          "shell.execute_reply.started": "2025-01-30T09:05:10.667374Z",
          "shell.execute_reply": "2025-01-30T09:05:12.333859Z"
        },
        "id": "gT5n5ZaxxnhW",
        "outputId": "61144898-08fd-4193-d1e2-b0417a0915e0"
      },
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(404351, 6)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T09:05:12.335476Z",
          "iopub.execute_input": "2025-01-30T09:05:12.335803Z",
          "iopub.status.idle": "2025-01-30T09:05:12.356422Z",
          "shell.execute_reply.started": "2025-01-30T09:05:12.335766Z",
          "shell.execute_reply": "2025-01-30T09:05:12.355562Z"
        },
        "id": "61vwRPnYxnhW",
        "outputId": "f1be219c-c4c5-41dd-9c32-051d9e83854d"
      },
      "outputs": [
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/plain": "   id  qid1  qid2                                          question1  \\\n0   0     1     2  What is the step by step guide to invest in sh...   \n1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n2   2     5     6  How can I increase the speed of my internet co...   \n3   3     7     8  Why am I mentally very lonely? How can I solve...   \n4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n\n                                           question2  is_duplicate  \n0  What is the step by step guide to invest in sh...             0  \n1  What would happen if the Indian government sto...             0  \n2  How can Internet speed be increased by hacking...             0  \n3  Find the remainder when [math]23^{24}[/math] i...             0  \n4            Which fish would survive in salt water?             0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>qid1</th>\n      <th>qid2</th>\n      <th>question1</th>\n      <th>question2</th>\n      <th>is_duplicate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>What is the step by step guide to invest in sh...</td>\n      <td>What is the step by step guide to invest in sh...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n      <td>What would happen if the Indian government sto...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>5</td>\n      <td>6</td>\n      <td>How can I increase the speed of my internet co...</td>\n      <td>How can Internet speed be increased by hacking...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>7</td>\n      <td>8</td>\n      <td>Why am I mentally very lonely? How can I solve...</td>\n      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>9</td>\n      <td>10</td>\n      <td>Which one dissolve in water quikly sugar, salt...</td>\n      <td>Which fish would survive in salt water?</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.value_counts('is_duplicate')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T09:05:12.357286Z",
          "iopub.execute_input": "2025-01-30T09:05:12.357807Z",
          "iopub.status.idle": "2025-01-30T09:05:12.377725Z",
          "shell.execute_reply.started": "2025-01-30T09:05:12.357766Z",
          "shell.execute_reply": "2025-01-30T09:05:12.377075Z"
        },
        "id": "4qvUHTYfxnhX",
        "outputId": "b366aaba-cf23-4082-b78f-f634e578c03b"
      },
      "outputs": [
        {
          "execution_count": 8,
          "output_type": "execute_result",
          "data": {
            "text/plain": "is_duplicate\n0    255045\n1    149306\nName: count, dtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#here since the data is quite unbalanced, we need to balance the data but undersampling\n",
        "class_0 = df[df['is_duplicate'] == 0 ]   ## majority class\n",
        "class_1 = df[df['is_duplicate'] == 1 ]   ## minority class\n",
        "\n",
        "\n",
        "class_0_undersampled = class_0.sample(n = len(class_1) , random_state = 42)\n",
        "\n",
        "sampled_df = pd.concat([class_0_undersampled, class_1], axis = 0).sample(frac=1, random_state=42)\n",
        "\n",
        "sampled_df\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T09:05:12.378647Z",
          "iopub.execute_input": "2025-01-30T09:05:12.378893Z",
          "iopub.status.idle": "2025-01-30T09:05:12.574875Z",
          "shell.execute_reply.started": "2025-01-30T09:05:12.378874Z",
          "shell.execute_reply": "2025-01-30T09:05:12.573995Z"
        },
        "id": "EpjaNRDLxnhX",
        "outputId": "398e1bca-26b9-473b-e276-01b7ce10cdc0"
      },
      "outputs": [
        {
          "execution_count": 9,
          "output_type": "execute_result",
          "data": {
            "text/plain": "            id    qid1    qid2  \\\n139827  139827  276792  276793   \n161175  161175  318664  318665   \n227921  227921  449170  449171   \n72941    72941  144954  144955   \n378149  378149  739656  739657   \n...        ...     ...     ...   \n120436  120436  238672  238673   \n295641  295641  580738  580739   \n231035  231035  455253  455254   \n50379    50379  100280  100281   \n87586    87586  173921  173922   \n\n                                                question1  \\\n139827  What is the importance of smart objects in Pho...   \n161175        How do I check who blocked me on Instagram?   \n227921  How essential is Brijmohan Agrawal's role in C...   \n72941   Why do some completely straight forward questi...   \n378149                    What are the features of java8?   \n...                                                   ...   \n120436                      Do Ray-Bans come with a case?   \n295641   What qualification is required for work in SEBI?   \n231035  How can we design a building which uses day li...   \n50379           Who are some bisexual/lesbian top models?   \n87586    What is it like for an Indian to live in Munich?   \n\n                                                question2  is_duplicate  \n139827               What is a smart object in Photoshop?             1  \n161175  Is there a way to find out who blocked me on I...             1  \n227921  How important is Brijmohan Agrawal's role in C...             1  \n72941   Why are some questions on Quora flagged as nee...             1  \n378149  Which course is suitable for MBA either HR and...             0  \n...                                                   ...           ...  \n120436    Where can I buy Ray-Ban 4195s at a cheap price?             0  \n295641  What are the qualifications required to get a ...             1  \n231035        Can I choose 安菁莉 or 安荧莉 as my Chinese name?             0  \n50379   I have come out as bisexual but I think I migh...             0  \n87586    In which country are Indians respected the most?             0  \n\n[298612 rows x 6 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>qid1</th>\n      <th>qid2</th>\n      <th>question1</th>\n      <th>question2</th>\n      <th>is_duplicate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>139827</th>\n      <td>139827</td>\n      <td>276792</td>\n      <td>276793</td>\n      <td>What is the importance of smart objects in Pho...</td>\n      <td>What is a smart object in Photoshop?</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>161175</th>\n      <td>161175</td>\n      <td>318664</td>\n      <td>318665</td>\n      <td>How do I check who blocked me on Instagram?</td>\n      <td>Is there a way to find out who blocked me on I...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>227921</th>\n      <td>227921</td>\n      <td>449170</td>\n      <td>449171</td>\n      <td>How essential is Brijmohan Agrawal's role in C...</td>\n      <td>How important is Brijmohan Agrawal's role in C...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>72941</th>\n      <td>72941</td>\n      <td>144954</td>\n      <td>144955</td>\n      <td>Why do some completely straight forward questi...</td>\n      <td>Why are some questions on Quora flagged as nee...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>378149</th>\n      <td>378149</td>\n      <td>739656</td>\n      <td>739657</td>\n      <td>What are the features of java8?</td>\n      <td>Which course is suitable for MBA either HR and...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>120436</th>\n      <td>120436</td>\n      <td>238672</td>\n      <td>238673</td>\n      <td>Do Ray-Bans come with a case?</td>\n      <td>Where can I buy Ray-Ban 4195s at a cheap price?</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>295641</th>\n      <td>295641</td>\n      <td>580738</td>\n      <td>580739</td>\n      <td>What qualification is required for work in SEBI?</td>\n      <td>What are the qualifications required to get a ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>231035</th>\n      <td>231035</td>\n      <td>455253</td>\n      <td>455254</td>\n      <td>How can we design a building which uses day li...</td>\n      <td>Can I choose 安菁莉 or 安荧莉 as my Chinese name?</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>50379</th>\n      <td>50379</td>\n      <td>100280</td>\n      <td>100281</td>\n      <td>Who are some bisexual/lesbian top models?</td>\n      <td>I have come out as bisexual but I think I migh...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>87586</th>\n      <td>87586</td>\n      <td>173921</td>\n      <td>173922</td>\n      <td>What is it like for an Indian to live in Munich?</td>\n      <td>In which country are Indians respected the most?</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>298612 rows × 6 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "##data pre processing\n",
        "def preprocess(q):\n",
        "    #lowercase and removed leading and trailing spaces\n",
        "    q = str(q).lower().strip()\n",
        "\n",
        "    # Replace certain special characters with their string equivalents\n",
        "    q = q.replace('%', ' percent')\n",
        "    q = q.replace('$', ' dollar ')\n",
        "    q = q.replace('₹', ' rupee ')\n",
        "    q = q.replace('€', ' euro ')\n",
        "    q = q.replace('@', ' at ')\n",
        "\n",
        "    # The pattern '[math]' appears around 900 times in the whole dataset.\n",
        "    q = q.replace('[math]', '')\n",
        "\n",
        "    # Replacing some numbers with string equivalents (not perfect, can be done better to account for more cases)\n",
        "    q = q.replace(',000,000,000 ', 'b ')\n",
        "    q = q.replace(',000,000 ', 'm ')\n",
        "    q = q.replace(',000 ', 'k ')\n",
        "    q = re.sub(r'([0-9]+)000000000', r'\\1b', q)\n",
        "    q = re.sub(r'([0-9]+)000000', r'\\1m', q)\n",
        "    q = re.sub(r'([0-9]+)000', r'\\1k', q)\n",
        "\n",
        "    # Decontracting words\n",
        "    # https://en.wikipedia.org/wiki/Wikipedia%3aList_of_English_contractions\n",
        "    # https://stackoverflow.com/a/19794953\n",
        "    contractions = {\n",
        "    \"ain't\": \"am not\",\n",
        "    \"aren't\": \"are not\",\n",
        "    \"can't\": \"can not\",\n",
        "    \"can't've\": \"can not have\",\n",
        "    \"'cause\": \"because\",\n",
        "    \"could've\": \"could have\",\n",
        "    \"couldn't\": \"could not\",\n",
        "    \"couldn't've\": \"could not have\",\n",
        "    \"didn't\": \"did not\",\n",
        "    \"doesn't\": \"does not\",\n",
        "    \"don't\": \"do not\",\n",
        "    \"hadn't\": \"had not\",\n",
        "    \"hadn't've\": \"had not have\",\n",
        "    \"hasn't\": \"has not\",\n",
        "    \"haven't\": \"have not\",\n",
        "    \"he'd\": \"he would\",\n",
        "    \"he'd've\": \"he would have\",\n",
        "    \"he'll\": \"he will\",\n",
        "    \"he'll've\": \"he will have\",\n",
        "    \"he's\": \"he is\",\n",
        "    \"how'd\": \"how did\",\n",
        "    \"how'd'y\": \"how do you\",\n",
        "    \"how'll\": \"how will\",\n",
        "    \"how's\": \"how is\",\n",
        "    \"i'd\": \"i would\",\n",
        "    \"i'd've\": \"i would have\",\n",
        "    \"i'll\": \"i will\",\n",
        "    \"i'll've\": \"i will have\",\n",
        "    \"i'm\": \"i am\",\n",
        "    \"i've\": \"i have\",\n",
        "    \"isn't\": \"is not\",\n",
        "    \"it'd\": \"it would\",\n",
        "    \"it'd've\": \"it would have\",\n",
        "    \"it'll\": \"it will\",\n",
        "    \"it'll've\": \"it will have\",\n",
        "    \"it's\": \"it is\",\n",
        "    \"let's\": \"let us\",\n",
        "    \"ma'am\": \"madam\",\n",
        "    \"mayn't\": \"may not\",\n",
        "    \"might've\": \"might have\",\n",
        "    \"mightn't\": \"might not\",\n",
        "    \"mightn't've\": \"might not have\",\n",
        "    \"must've\": \"must have\",\n",
        "    \"mustn't\": \"must not\",\n",
        "    \"mustn't've\": \"must not have\",\n",
        "    \"needn't\": \"need not\",\n",
        "    \"needn't've\": \"need not have\",\n",
        "    \"o'clock\": \"of the clock\",\n",
        "    \"oughtn't\": \"ought not\",\n",
        "    \"oughtn't've\": \"ought not have\",\n",
        "    \"shan't\": \"shall not\",\n",
        "    \"sha'n't\": \"shall not\",\n",
        "    \"shan't've\": \"shall not have\",\n",
        "    \"she'd\": \"she would\",\n",
        "    \"she'd've\": \"she would have\",\n",
        "    \"she'll\": \"she will\",\n",
        "    \"she'll've\": \"she will have\",\n",
        "    \"she's\": \"she is\",\n",
        "    \"should've\": \"should have\",\n",
        "    \"shouldn't\": \"should not\",\n",
        "    \"shouldn't've\": \"should not have\",\n",
        "    \"so've\": \"so have\",\n",
        "    \"so's\": \"so as\",\n",
        "    \"that'd\": \"that would\",\n",
        "    \"that'd've\": \"that would have\",\n",
        "    \"that's\": \"that is\",\n",
        "    \"there'd\": \"there would\",\n",
        "    \"there'd've\": \"there would have\",\n",
        "    \"there's\": \"there is\",\n",
        "    \"they'd\": \"they would\",\n",
        "    \"they'd've\": \"they would have\",\n",
        "    \"they'll\": \"they will\",\n",
        "    \"they'll've\": \"they will have\",\n",
        "    \"they're\": \"they are\",\n",
        "    \"they've\": \"they have\",\n",
        "    \"to've\": \"to have\",\n",
        "    \"wasn't\": \"was not\",\n",
        "    \"we'd\": \"we would\",\n",
        "    \"we'd've\": \"we would have\",\n",
        "    \"we'll\": \"we will\",\n",
        "    \"we'll've\": \"we will have\",\n",
        "    \"we're\": \"we are\",\n",
        "    \"we've\": \"we have\",\n",
        "    \"weren't\": \"were not\",\n",
        "    \"what'll\": \"what will\",\n",
        "    \"what'll've\": \"what will have\",\n",
        "    \"what're\": \"what are\",\n",
        "    \"what's\": \"what is\",\n",
        "    \"what've\": \"what have\",\n",
        "    \"when's\": \"when is\",\n",
        "    \"when've\": \"when have\",\n",
        "    \"where'd\": \"where did\",\n",
        "    \"where's\": \"where is\",\n",
        "    \"where've\": \"where have\",\n",
        "    \"who'll\": \"who will\",\n",
        "    \"who'll've\": \"who will have\",\n",
        "    \"who's\": \"who is\",\n",
        "    \"who've\": \"who have\",\n",
        "    \"why's\": \"why is\",\n",
        "    \"why've\": \"why have\",\n",
        "    \"will've\": \"will have\",\n",
        "    \"won't\": \"will not\",\n",
        "    \"won't've\": \"will not have\",\n",
        "    \"would've\": \"would have\",\n",
        "    \"wouldn't\": \"would not\",\n",
        "    \"wouldn't've\": \"would not have\",\n",
        "    \"y'all\": \"you all\",\n",
        "    \"y'all'd\": \"you all would\",\n",
        "    \"y'all'd've\": \"you all would have\",\n",
        "    \"y'all're\": \"you all are\",\n",
        "    \"y'all've\": \"you all have\",\n",
        "    \"you'd\": \"you would\",\n",
        "    \"you'd've\": \"you would have\",\n",
        "    \"you'll\": \"you will\",\n",
        "    \"you'll've\": \"you will have\",\n",
        "    \"you're\": \"you are\",\n",
        "    \"you've\": \"you have\"\n",
        "    }\n",
        "\n",
        "    q_decontracted = []\n",
        "\n",
        "    for word in q.split():\n",
        "        if word in contractions:\n",
        "            word = contractions[word]\n",
        "\n",
        "        q_decontracted.append(word)\n",
        "\n",
        "    q = ' '.join(q_decontracted)\n",
        "    q = q.replace(\"'ve\", \" have\")\n",
        "    q = q.replace(\"n't\", \" not\")\n",
        "    q = q.replace(\"'re\", \" are\")\n",
        "    q = q.replace(\"'ll\", \" will\")\n",
        "\n",
        "    # Removing HTML tags\n",
        "    q = BeautifulSoup(q)\n",
        "    q = q.get_text()\n",
        "\n",
        "    # Remove punctuations\n",
        "    pattern = re.compile('\\W')\n",
        "    q = re.sub(pattern,' ', q).strip()\n",
        "\n",
        "\n",
        "    return q"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T09:05:12.577245Z",
          "iopub.execute_input": "2025-01-30T09:05:12.577472Z",
          "iopub.status.idle": "2025-01-30T09:05:12.589516Z",
          "shell.execute_reply.started": "2025-01-30T09:05:12.577454Z",
          "shell.execute_reply": "2025-01-30T09:05:12.588694Z"
        },
        "id": "wGAbZlz-xnhX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess(\"I've already! wasn't <b>done</b>?\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T09:05:12.590918Z",
          "iopub.execute_input": "2025-01-30T09:05:12.591182Z",
          "iopub.status.idle": "2025-01-30T09:05:12.613418Z",
          "shell.execute_reply.started": "2025-01-30T09:05:12.591162Z",
          "shell.execute_reply": "2025-01-30T09:05:12.612646Z"
        },
        "id": "cSffRl_BxnhY",
        "outputId": "83505651-d039-4afd-afb7-b2c95ba4c963"
      },
      "outputs": [
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'i have already  was not done'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_df['question1'] = sampled_df['question1'].apply(preprocess)\n",
        "sampled_df['question2'] = sampled_df['question2'].apply(preprocess)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T09:05:12.614288Z",
          "iopub.execute_input": "2025-01-30T09:05:12.614618Z",
          "iopub.status.idle": "2025-01-30T09:07:13.517824Z",
          "shell.execute_reply.started": "2025-01-30T09:05:12.614585Z",
          "shell.execute_reply": "2025-01-30T09:07:13.516804Z"
        },
        "id": "ezo09IN7xnhY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_df.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T09:07:13.518754Z",
          "iopub.execute_input": "2025-01-30T09:07:13.519021Z",
          "iopub.status.idle": "2025-01-30T09:07:13.528754Z",
          "shell.execute_reply.started": "2025-01-30T09:07:13.519001Z",
          "shell.execute_reply": "2025-01-30T09:07:13.527879Z"
        },
        "id": "_idjr5w1xnhY",
        "outputId": "d6dff6ca-ed28-4c12-b48a-67b62b436b0c"
      },
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "            id    qid1    qid2  \\\n139827  139827  276792  276793   \n161175  161175  318664  318665   \n227921  227921  449170  449171   \n72941    72941  144954  144955   \n378149  378149  739656  739657   \n\n                                                question1  \\\n139827  what is the importance of smart objects in pho...   \n161175         how do i check who blocked me on instagram   \n227921  how essential is brijmohan agrawal s role in c...   \n72941   why do some completely straight forward questi...   \n378149                     what are the features of java8   \n\n                                                question2  is_duplicate  \n139827                what is a smart object in photoshop             1  \n161175  is there a way to find out who blocked me on i...             1  \n227921  how important is brijmohan agrawal s role in c...             1  \n72941   why are some questions on quora flagged as nee...             1  \n378149  which course is suitable for mba either hr and...             0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>qid1</th>\n      <th>qid2</th>\n      <th>question1</th>\n      <th>question2</th>\n      <th>is_duplicate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>139827</th>\n      <td>139827</td>\n      <td>276792</td>\n      <td>276793</td>\n      <td>what is the importance of smart objects in pho...</td>\n      <td>what is a smart object in photoshop</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>161175</th>\n      <td>161175</td>\n      <td>318664</td>\n      <td>318665</td>\n      <td>how do i check who blocked me on instagram</td>\n      <td>is there a way to find out who blocked me on i...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>227921</th>\n      <td>227921</td>\n      <td>449170</td>\n      <td>449171</td>\n      <td>how essential is brijmohan agrawal s role in c...</td>\n      <td>how important is brijmohan agrawal s role in c...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>72941</th>\n      <td>72941</td>\n      <td>144954</td>\n      <td>144955</td>\n      <td>why do some completely straight forward questi...</td>\n      <td>why are some questions on quora flagged as nee...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>378149</th>\n      <td>378149</td>\n      <td>739656</td>\n      <td>739657</td>\n      <td>what are the features of java8</td>\n      <td>which course is suitable for mba either hr and...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#checking if there is no null values in our dataset\n",
        "sampled_df.isnull().sum()\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T09:07:13.529582Z",
          "iopub.execute_input": "2025-01-30T09:07:13.529802Z",
          "iopub.status.idle": "2025-01-30T09:07:13.938488Z",
          "shell.execute_reply.started": "2025-01-30T09:07:13.529783Z",
          "shell.execute_reply": "2025-01-30T09:07:13.937682Z"
        },
        "id": "o5lCh9H8xnhZ",
        "outputId": "1e39d33d-97e1-49ae-8b71-a9b8f86327b5"
      },
      "outputs": [
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#removing stopwords from our dataset\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    words = word_tokenize(text)  # Tokenize and convert to lowercase\n",
        "    filtered_words = [word for word in words if word not in stop_words]\n",
        "    return \" \".join(filtered_words)\n",
        "\n",
        "\n",
        "sampled_df['question1'] = sampled_df[\"question1\"].apply(remove_stopwords)\n",
        "sampled_df['question2'] = sampled_df[\"question2\"].apply(remove_stopwords)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T09:07:13.939348Z",
          "iopub.execute_input": "2025-01-30T09:07:13.939663Z",
          "iopub.status.idle": "2025-01-30T09:09:40.08069Z",
          "shell.execute_reply.started": "2025-01-30T09:07:13.939626Z",
          "shell.execute_reply": "2025-01-30T09:09:40.079949Z"
        },
        "id": "XfK4aVqIxnhZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_df.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T09:09:40.081535Z",
          "iopub.execute_input": "2025-01-30T09:09:40.081869Z",
          "iopub.status.idle": "2025-01-30T09:09:40.090952Z",
          "shell.execute_reply.started": "2025-01-30T09:09:40.081839Z",
          "shell.execute_reply": "2025-01-30T09:09:40.090031Z"
        },
        "id": "Wg-qQjWVxnhZ",
        "outputId": "50acffcb-85fa-49ad-8895-ede704c45dad"
      },
      "outputs": [
        {
          "execution_count": 16,
          "output_type": "execute_result",
          "data": {
            "text/plain": "            id    qid1    qid2  \\\n139827  139827  276792  276793   \n161175  161175  318664  318665   \n227921  227921  449170  449171   \n72941    72941  144954  144955   \n378149  378149  739656  739657   \n\n                                                question1  \\\n139827                 importance smart objects photoshop   \n161175                            check blocked instagram   \n227921  essential brijmohan agrawal role chhattisgarh ...   \n72941   completely straight forward questions get mark...   \n378149                                     features java8   \n\n                                                question2  is_duplicate  \n139827                             smart object photoshop             1  \n161175                         way find blocked instagram             1  \n227921  important brijmohan agrawal role chhattisgarh ...             1  \n72941   questions quora flagged needing improvement ne...             1  \n378149            course suitable mba either hr marketing             0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>qid1</th>\n      <th>qid2</th>\n      <th>question1</th>\n      <th>question2</th>\n      <th>is_duplicate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>139827</th>\n      <td>139827</td>\n      <td>276792</td>\n      <td>276793</td>\n      <td>importance smart objects photoshop</td>\n      <td>smart object photoshop</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>161175</th>\n      <td>161175</td>\n      <td>318664</td>\n      <td>318665</td>\n      <td>check blocked instagram</td>\n      <td>way find blocked instagram</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>227921</th>\n      <td>227921</td>\n      <td>449170</td>\n      <td>449171</td>\n      <td>essential brijmohan agrawal role chhattisgarh ...</td>\n      <td>important brijmohan agrawal role chhattisgarh ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>72941</th>\n      <td>72941</td>\n      <td>144954</td>\n      <td>144955</td>\n      <td>completely straight forward questions get mark...</td>\n      <td>questions quora flagged needing improvement ne...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>378149</th>\n      <td>378149</td>\n      <td>739656</td>\n      <td>739657</td>\n      <td>features java8</td>\n      <td>course suitable mba either hr marketing</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#dropping the unwanted columns\n",
        "final_df = sampled_df.drop(columns = ['id' , 'qid1' , 'qid2'])\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T09:09:40.091942Z",
          "iopub.execute_input": "2025-01-30T09:09:40.092329Z",
          "iopub.status.idle": "2025-01-30T09:09:40.119534Z",
          "shell.execute_reply.started": "2025-01-30T09:09:40.092305Z",
          "shell.execute_reply": "2025-01-30T09:09:40.118906Z"
        },
        "id": "KLDESIQSxnhZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T09:09:40.120172Z",
          "iopub.execute_input": "2025-01-30T09:09:40.120377Z",
          "iopub.status.idle": "2025-01-30T09:09:40.128657Z",
          "shell.execute_reply.started": "2025-01-30T09:09:40.120359Z",
          "shell.execute_reply": "2025-01-30T09:09:40.127901Z"
        },
        "id": "HItcVLONxnhZ",
        "outputId": "72dd7c85-5c79-49d8-8aa6-eb2f6e77f2cd"
      },
      "outputs": [
        {
          "execution_count": 18,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                                question1  \\\n139827                 importance smart objects photoshop   \n161175                            check blocked instagram   \n227921  essential brijmohan agrawal role chhattisgarh ...   \n72941   completely straight forward questions get mark...   \n378149                                     features java8   \n\n                                                question2  is_duplicate  \n139827                             smart object photoshop             1  \n161175                         way find blocked instagram             1  \n227921  important brijmohan agrawal role chhattisgarh ...             1  \n72941   questions quora flagged needing improvement ne...             1  \n378149            course suitable mba either hr marketing             0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question1</th>\n      <th>question2</th>\n      <th>is_duplicate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>139827</th>\n      <td>importance smart objects photoshop</td>\n      <td>smart object photoshop</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>161175</th>\n      <td>check blocked instagram</td>\n      <td>way find blocked instagram</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>227921</th>\n      <td>essential brijmohan agrawal role chhattisgarh ...</td>\n      <td>important brijmohan agrawal role chhattisgarh ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>72941</th>\n      <td>completely straight forward questions get mark...</td>\n      <td>questions quora flagged needing improvement ne...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>378149</th>\n      <td>features java8</td>\n      <td>course suitable mba either hr marketing</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "x = final_df[['question1' , 'question2']]\n",
        "y = final_df[['is_duplicate']]\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T09:09:40.129407Z",
          "iopub.execute_input": "2025-01-30T09:09:40.129664Z",
          "iopub.status.idle": "2025-01-30T09:09:40.224072Z",
          "shell.execute_reply.started": "2025-01-30T09:09:40.129637Z",
          "shell.execute_reply": "2025-01-30T09:09:40.223372Z"
        },
        "id": "HZf09aP7xnhZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Embedding, Bidirectional, LSTM, Dense, Dropout, Attention, GlobalMaxPooling1D, GlobalAveragePooling1D, Concatenate\n",
        ")\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T09:09:40.22493Z",
          "iopub.execute_input": "2025-01-30T09:09:40.225233Z",
          "iopub.status.idle": "2025-01-30T09:09:40.235318Z",
          "shell.execute_reply.started": "2025-01-30T09:09:40.225211Z",
          "shell.execute_reply": "2025-01-30T09:09:40.234524Z"
        },
        "id": "SGltH9Gkxnha"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "x[\"question1\"] = x[\"question1\"].apply(lambda x: str(x).lower() if isinstance(x, str) else \"\")\n",
        "x[\"question2\"] = x[\"question2\"].apply(lambda x: str(x).lower() if isinstance(x, str) else \"\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T09:09:40.236206Z",
          "iopub.execute_input": "2025-01-30T09:09:40.23642Z",
          "iopub.status.idle": "2025-01-30T09:09:40.480148Z",
          "shell.execute_reply.started": "2025-01-30T09:09:40.236402Z",
          "shell.execute_reply": "2025-01-30T09:09:40.479373Z"
        },
        "id": "4b-pkIihxnha"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODEL BUILDING**"
      ],
      "metadata": {
        "id": "P1SVgJCxxnha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"thanakomsn/glove6b300dtxt\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T09:09:40.480991Z",
          "iopub.execute_input": "2025-01-30T09:09:40.481246Z",
          "iopub.status.idle": "2025-01-30T09:09:40.603296Z",
          "shell.execute_reply.started": "2025-01-30T09:09:40.481224Z",
          "shell.execute_reply": "2025-01-30T09:09:40.602402Z"
        },
        "id": "rqZXCvQYxnhb",
        "outputId": "62b3598e-251a-4a37-bcec-0bb876c2afc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Path to dataset files: /kaggle/input/glove6b300dtxt\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "glove_file = \"/kaggle/input/glove6b300dtxt/glove.6B.300d.txt\"\n",
        "embedding_dim = 300\n",
        "embeddings_index = {}\n",
        "\n",
        "with open(glove_file, encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vectors = np.asarray(values[1:], dtype=\"float32\")\n",
        "        embeddings_index[word] = vectors\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train[\"question1\"].tolist() + X_train[\"question2\"].tolist())\n",
        "tokenizer.fit_on_texts(X_test[\"question1\"].tolist() + X_test[\"question2\"].tolist())\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T09:09:40.60424Z",
          "iopub.execute_input": "2025-01-30T09:09:40.604499Z",
          "iopub.status.idle": "2025-01-30T09:10:13.912472Z",
          "shell.execute_reply.started": "2025-01-30T09:09:40.604468Z",
          "shell.execute_reply": "2025-01-30T09:10:13.911792Z"
        },
        "id": "2pf9KJ2cxnhb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "q1_sequences_train = tokenizer.texts_to_sequences(X_train[\"question1\"])\n",
        "q2_sequences_train = tokenizer.texts_to_sequences(X_train[\"question2\"])\n",
        "q1_sequences_test = tokenizer.texts_to_sequences(X_test[\"question1\"])\n",
        "q2_sequences_test = tokenizer.texts_to_sequences(X_test[\"question2\"])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T09:10:13.91341Z",
          "iopub.execute_input": "2025-01-30T09:10:13.91373Z",
          "iopub.status.idle": "2025-01-30T09:10:19.983813Z",
          "shell.execute_reply.started": "2025-01-30T09:10:13.913699Z",
          "shell.execute_reply": "2025-01-30T09:10:19.983154Z"
        },
        "id": "x9_6r1Raxnhb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(q1_sequences_test))\n",
        "print(len(y_test))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T09:10:19.987228Z",
          "iopub.execute_input": "2025-01-30T09:10:19.987464Z",
          "iopub.status.idle": "2025-01-30T09:10:19.992109Z",
          "shell.execute_reply.started": "2025-01-30T09:10:19.987446Z",
          "shell.execute_reply": "2025-01-30T09:10:19.991137Z"
        },
        "id": "Ahbuc7nFxnhb",
        "outputId": "21b428b5-ee28-4279-cc34-0157e54fec69"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "59723\n59723\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "max_len1 = max(len(seq) for seq in q1_sequences_train)\n",
        "max_len2 = max(len(seq) for seq in q2_sequences_train)\n",
        "max_len3 = max(len(seq) for seq in q2_sequences_test)\n",
        "max_len4 = max(len(seq) for seq in q2_sequences_test)\n",
        "max_len = max(max_len1 , max_len2 ,max_len3,max_len4 )\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T09:10:19.993132Z",
          "iopub.execute_input": "2025-01-30T09:10:19.993319Z",
          "iopub.status.idle": "2025-01-30T09:10:20.059201Z",
          "shell.execute_reply.started": "2025-01-30T09:10:19.993303Z",
          "shell.execute_reply": "2025-01-30T09:10:20.058487Z"
        },
        "id": "BodDPXRMxnhb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "q1_padded_train = pad_sequences(q1_sequences_train, maxlen=max_len, padding=\"post\")\n",
        "q2_padded_train = pad_sequences(q2_sequences_train, maxlen=max_len, padding=\"post\")\n",
        "q1_padded_test = pad_sequences(q1_sequences_test, maxlen=max_len, padding=\"post\")\n",
        "q2_padded_test = pad_sequences(q2_sequences_test, maxlen=max_len, padding=\"post\")\n",
        "x1_train = [q1_padded_train , q2_padded_train]\n",
        "x1_test = [q1_padded_test , q2_padded_test]\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T09:10:20.059977Z",
          "iopub.execute_input": "2025-01-30T09:10:20.060256Z",
          "iopub.status.idle": "2025-01-30T09:10:21.349547Z",
          "shell.execute_reply.started": "2025-01-30T09:10:20.060229Z",
          "shell.execute_reply": "2025-01-30T09:10:21.348889Z"
        },
        "id": "PwzSnPUbxnhb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T09:10:21.350254Z",
          "iopub.execute_input": "2025-01-30T09:10:21.350491Z",
          "iopub.status.idle": "2025-01-30T09:10:21.579Z",
          "shell.execute_reply.started": "2025-01-30T09:10:21.350472Z",
          "shell.execute_reply": "2025-01-30T09:10:21.578223Z"
        },
        "id": "9JPE88vMxnhb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Positional Encoding (Sinusoidal)\n",
        "def get_sinusoidal_encoding(max_len, embedding_dim):\n",
        "    position = np.arange(max_len)[:, np.newaxis]\n",
        "    div_term = np.exp(np.arange(0, embedding_dim, 2) * -(np.log(10000.0) / embedding_dim))\n",
        "\n",
        "    pos_enc = np.zeros((max_len, embedding_dim))\n",
        "    pos_enc[:, 0::2] = np.sin(position * div_term)\n",
        "    pos_enc[:, 1::2] = np.cos(position * div_term)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T09:10:21.579802Z",
          "iopub.execute_input": "2025-01-30T09:10:21.580078Z",
          "iopub.status.idle": "2025-01-30T09:10:21.584875Z",
          "shell.execute_reply.started": "2025-01-30T09:10:21.580053Z",
          "shell.execute_reply": "2025-01-30T09:10:21.584136Z"
        },
        "id": "kNTWH1AQxnhc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    input_q1 = Input(shape=(max_len,))\n",
        "    input_q2 = Input(shape=(max_len,))\n",
        "\n",
        "    # Shared embedding layer (frozen)\n",
        "    embedding_layer = Embedding(\n",
        "        input_dim=len(word_index) + 1,\n",
        "        output_dim=embedding_dim,\n",
        "        weights=[embedding_matrix],\n",
        "        input_length=max_len,\n",
        "        trainable=False,\n",
        "    )\n",
        "\n",
        "# Embedding layers for both questions\n",
        "    embedded_q1 = embedding_layer(input_q1)\n",
        "    embedded_q2 = embedding_layer(input_q2)\n",
        "\n",
        "# LSTM layers\n",
        "    lstm_q1 = Bidirectional(LSTM(64, return_sequences=True))(embedded_q1)\n",
        "    lstm_q2 = Bidirectional(LSTM(64, return_sequences=True))(embedded_q2)\n",
        "\n",
        "# Attention mechanism\n",
        "    attention_q1 = GlobalMaxPooling1D()(lstm_q1)\n",
        "    attention_q2 = GlobalMaxPooling1D()(lstm_q2)\n",
        "\n",
        "# Combine features\n",
        "    combined = Concatenate()([attention_q1, attention_q2])\n",
        "\n",
        "# Dense layers\n",
        "    dense = Dense(128, activation=\"relu\")(combined)\n",
        "    dropout = Dropout(0.3)(dense)\n",
        "    output = Dense(1, activation=\"sigmoid\")(dropout)\n",
        "\n",
        "    # Create the model\n",
        "    model = Model(inputs=[input_q1, input_q2], outputs=output)\n",
        "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T09:10:21.585718Z",
          "iopub.execute_input": "2025-01-30T09:10:21.585978Z",
          "iopub.status.idle": "2025-01-30T09:10:24.380948Z",
          "shell.execute_reply.started": "2025-01-30T09:10:21.585942Z",
          "shell.execute_reply": "2025-01-30T09:10:24.380138Z"
        },
        "id": "cL_vMIxbxnhc",
        "outputId": "af011764-9374-48b2-b25b-be0380fb217c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1mModel: \"functional\"\u001b[0m\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m103\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m103\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m103\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │     \u001b[38;5;34m20,968,800\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n│                           │                        │                │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ bidirectional             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m103\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m186,880\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBidirectional\u001b[0m)           │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ bidirectional_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m103\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m186,880\u001b[0m │ embedding[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mBidirectional\u001b[0m)           │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_max_pooling1d      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_max_pooling1d_1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ bidirectional_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ global_max_pooling1d[\u001b[38;5;34m…\u001b[0m │\n│                           │                        │                │ global_max_pooling1d_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m32,896\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m129\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,968,800</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n│                           │                        │                │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ bidirectional             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">186,880</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)           │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ bidirectional_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">186,880</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)           │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_max_pooling1d      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_max_pooling1d_1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                           │                        │                │ global_max_pooling1d_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,375,585\u001b[0m (81.54 MB)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,375,585</span> (81.54 MB)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m406,785\u001b[0m (1.55 MB)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">406,785</span> (1.55 MB)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m20,968,800\u001b[0m (79.99 MB)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,968,800</span> (79.99 MB)\n</pre>\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Positional Encoding (Sinusoidal)\n",
        "def get_sinusoidal_encoding(max_len, embedding_dim):\n",
        "    position = np.arange(max_len)[:, np.newaxis]\n",
        "    div_term = np.exp(np.arange(0, embedding_dim, 2) * -(np.log(10000.0) / embedding_dim))\n",
        "\n",
        "    pos_enc = np.zeros((max_len, embedding_dim))\n",
        "    pos_enc[:, 0::2] = np.sin(position * div_term)\n",
        "    pos_enc[:, 1::2] = np.cos(position * div_term)\n",
        "\n",
        "    return tf.convert_to_tensor(pos_enc, dtype=tf.float32)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T09:10:24.38183Z",
          "iopub.execute_input": "2025-01-30T09:10:24.382087Z",
          "iopub.status.idle": "2025-01-30T09:10:24.386996Z",
          "shell.execute_reply.started": "2025-01-30T09:10:24.382067Z",
          "shell.execute_reply": "2025-01-30T09:10:24.386157Z"
        },
        "id": "c0K7Ef1nxnhc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformer Block (Self-Attention + Feedforward Layer)\n",
        "def transformer_block(inputs, embedding_dim, num_heads, ff_dim, dropout_rate=0.1):\n",
        "    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim)(inputs, inputs)\n",
        "    attn_output = Dropout(dropout_rate)(attn_output)\n",
        "    out1 = LayerNormalization(epsilon=1e-6)(inputs + attn_output)\n",
        "\n",
        "    ffn = Dense(ff_dim, activation='relu')(out1)\n",
        "    ffn = Dense(embedding_dim)(ffn)\n",
        "    ffn = Dropout(dropout_rate)(ffn)\n",
        "    out2 = LayerNormalization(epsilon=1e-6)(out1 + ffn)\n",
        "\n",
        "    return out2"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T09:10:24.387993Z",
          "iopub.execute_input": "2025-01-30T09:10:24.388358Z",
          "iopub.status.idle": "2025-01-30T09:10:24.405409Z",
          "shell.execute_reply.started": "2025-01-30T09:10:24.388314Z",
          "shell.execute_reply": "2025-01-30T09:10:24.40426Z"
        },
        "id": "U4AJc2azxnhc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, Dropout, LayerNormalization, MultiHeadAttention, GlobalMaxPooling1D, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "num_heads = 4  # Number of attention heads\n",
        "ff_dim = 256  # Feedforward dimension\n",
        "# Inputs\n",
        "input_q1 = Input(shape=(max_len,))\n",
        "input_q2 = Input(shape=(max_len,))\n",
        "\n",
        "# Shared Embedding Layer (GloVe + Positional Encoding)\n",
        "embedding_layer = Embedding(input_dim=len(word_index) + 1,\n",
        "                            output_dim=embedding_dim,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=max_len,\n",
        "                            trainable=False)\n",
        "# embedded_q1 = embedding_layer(input_q1) + get_sinusoidal_encoding(max_len, embedding_dim)\n",
        "# embedded_q2 = embedding_layer(input_q2) + get_sinusoidal_encoding(max_len, embedding_dim)\n",
        "\n",
        "embedded_q1 = embedding_layer(input_q1)\n",
        "embedded_q2 = embedding_layer(input_q2)\n",
        "\n",
        "# Transformer Encoder Blocks\n",
        "transformer_q1 = transformer_block(embedded_q1, embedding_dim, num_heads, ff_dim)\n",
        "transformer_q2 = transformer_block(embedded_q2, embedding_dim, num_heads, ff_dim)\n",
        "\n",
        "# Cross-Attention between Question 1 and Question 2\n",
        "cross_attention = MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim)(transformer_q1, transformer_q2)\n",
        "cross_attention = GlobalMaxPooling1D()(cross_attention)\n",
        "\n",
        "# Feature Fusion and Dense Layers\n",
        "combined = Concatenate()([GlobalMaxPooling1D()(transformer_q1), GlobalMaxPooling1D()(transformer_q2), cross_attention])\n",
        "dense = Dense(128, activation=\"relu\")(combined)\n",
        "dropout = Dropout(0.3)(dense)\n",
        "output = Dense(1, activation=\"sigmoid\")(dropout)\n",
        "\n",
        "# Define Model\n",
        "model = Model(inputs=[input_q1, input_q2], outputs=output)\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Model Summary\n",
        "model.summary()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T10:02:03.413713Z",
          "iopub.execute_input": "2025-01-30T10:02:03.414116Z",
          "iopub.status.idle": "2025-01-30T10:02:03.84997Z",
          "shell.execute_reply.started": "2025-01-30T10:02:03.414084Z",
          "shell.execute_reply": "2025-01-30T10:02:03.849175Z"
        },
        "id": "LCUbFv8lxnhc",
        "outputId": "e86719c6-30bc-4034-bec7-1b8d38435bb8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1mModel: \"functional_1\"\u001b[0m\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m103\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ input_layer_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m103\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m103\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │     \u001b[38;5;34m20,968,800\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│                           │                        │                │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m103\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │      \u001b[38;5;34m1,443,900\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m103\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │      \u001b[38;5;34m1,443,900\u001b[0m │ embedding_1[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ embedding_1[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m103\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention[\u001b[38;5;34m…\u001b[0m │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m103\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add (\u001b[38;5;33mAdd\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m103\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n│                           │                        │                │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_2 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m103\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ embedding_1[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n│                           │                        │                │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m103\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │            \u001b[38;5;34m600\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m103\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │            \u001b[38;5;34m600\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m103\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m77,056\u001b[0m │ layer_normalization[\u001b[38;5;34m0\u001b[0m… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_4 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m103\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m77,056\u001b[0m │ layer_normalization_2… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m103\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │         \u001b[38;5;34m77,100\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_5 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m103\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │         \u001b[38;5;34m77,100\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m103\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m103\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_1 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m103\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization[\u001b[38;5;34m0\u001b[0m… │\n│                           │                        │                │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_3 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m103\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_2… │\n│                           │                        │                │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m103\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │            \u001b[38;5;34m600\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m103\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │            \u001b[38;5;34m600\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_2    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m103\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │      \u001b[38;5;34m1,443,900\u001b[0m │ layer_normalization_1… │\n│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_max_pooling1d_3    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_1… │\n│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_max_pooling1d_4    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_3… │\n│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_max_pooling1d_2    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m900\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ global_max_pooling1d_… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ global_max_pooling1d_… │\n│                           │                        │                │ global_max_pooling1d_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_6 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m115,328\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_7 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m129\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ input_layer_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,968,800</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│                           │                        │                │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,443,900</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,443,900</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n│                           │                        │                │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n│                           │                        │                │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">77,056</span> │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">77,056</span> │ layer_normalization_2… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">77,100</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">77,100</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│                           │                        │                │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_2… │\n│                           │                        │                │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ layer_normalization_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ multi_head_attention_2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,443,900</span> │ layer_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_max_pooling1d_3    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_max_pooling1d_4    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_3… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_max_pooling1d_2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">900</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooling1d_… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ global_max_pooling1d_… │\n│                           │                        │                │ global_max_pooling1d_… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">115,328</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,726,669\u001b[0m (98.14 MB)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,726,669</span> (98.14 MB)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,757,869\u001b[0m (18.15 MB)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,757,869</span> (18.15 MB)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m20,968,800\u001b[0m (79.99 MB)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,968,800</span> (79.99 MB)\n</pre>\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "8vK7XVMHxnhc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T10:02:08.30257Z",
          "iopub.execute_input": "2025-01-30T10:02:08.302921Z",
          "iopub.status.idle": "2025-01-30T10:02:08.308316Z",
          "shell.execute_reply.started": "2025-01-30T10:02:08.302893Z",
          "shell.execute_reply": "2025-01-30T10:02:08.307336Z"
        },
        "id": "EH-YT4qKxnhc",
        "outputId": "da01f0a4-8405-4057-fbe0-7d8942c47434"
      },
      "outputs": [
        {
          "execution_count": 54,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(238889, 2)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',    # Monitor validation loss\n",
        "    patience=5,            # Stop training after 3 epochs with no improvement\n",
        "    restore_best_weights=True  # Restore the weights of the best epoch\n",
        ")\n",
        "\n",
        "# Train the model with early stopping\n",
        "\n",
        "\n",
        "histoty = model.fit([x1_train[0], x1_train[1]], y_train, validation_data=([x1_test[0], x1_test[1]], y_test), epochs=100, batch_size=128 , callbacks=[early_stopping])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T10:02:11.430742Z",
          "iopub.execute_input": "2025-01-30T10:02:11.431135Z",
          "iopub.status.idle": "2025-01-30T10:28:13.135479Z",
          "shell.execute_reply.started": "2025-01-30T10:02:11.431104Z",
          "shell.execute_reply": "2025-01-30T10:28:13.13457Z"
        },
        "id": "wUMz-R8Xxnhc",
        "outputId": "2cce2ed5-effa-4ff8-bc98-a56d39fe9593"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/100\n\u001b[1m1867/1867\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 88ms/step - accuracy: 0.6415 - loss: 0.6451 - val_accuracy: 0.6997 - val_loss: 0.5759\nEpoch 2/100\n\u001b[1m1867/1867\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 82ms/step - accuracy: 0.7116 - loss: 0.5567 - val_accuracy: 0.7223 - val_loss: 0.5410\nEpoch 3/100\n\u001b[1m1867/1867\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 82ms/step - accuracy: 0.7278 - loss: 0.5357 - val_accuracy: 0.7268 - val_loss: 0.5386\nEpoch 4/100\n\u001b[1m1867/1867\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 82ms/step - accuracy: 0.7290 - loss: 0.5329 - val_accuracy: 0.7225 - val_loss: 0.5369\nEpoch 5/100\n\u001b[1m1867/1867\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 82ms/step - accuracy: 0.7412 - loss: 0.5144 - val_accuracy: 0.7334 - val_loss: 0.5244\nEpoch 6/100\n\u001b[1m1867/1867\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 82ms/step - accuracy: 0.7457 - loss: 0.5096 - val_accuracy: 0.7300 - val_loss: 0.5388\nEpoch 7/100\n\u001b[1m1867/1867\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 82ms/step - accuracy: 0.7541 - loss: 0.4970 - val_accuracy: 0.7333 - val_loss: 0.5285\nEpoch 8/100\n\u001b[1m1867/1867\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 82ms/step - accuracy: 0.7627 - loss: 0.4870 - val_accuracy: 0.7287 - val_loss: 0.5337\nEpoch 9/100\n\u001b[1m1867/1867\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 82ms/step - accuracy: 0.7679 - loss: 0.4792 - val_accuracy: 0.7383 - val_loss: 0.5388\nEpoch 10/100\n\u001b[1m1867/1867\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 82ms/step - accuracy: 0.7732 - loss: 0.4701 - val_accuracy: 0.7311 - val_loss: 0.5353\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"semantic_LSTM.keras\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T09:50:03.106434Z",
          "iopub.execute_input": "2025-01-30T09:50:03.106763Z",
          "iopub.status.idle": "2025-01-30T09:50:03.682997Z",
          "shell.execute_reply.started": "2025-01-30T09:50:03.106739Z",
          "shell.execute_reply": "2025-01-30T09:50:03.681922Z"
        },
        "id": "m_bnK8Egxnhd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"semantic_TRNSFRM.keras\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T10:29:28.58548Z",
          "iopub.execute_input": "2025-01-30T10:29:28.585805Z",
          "iopub.status.idle": "2025-01-30T10:29:29.292322Z",
          "shell.execute_reply.started": "2025-01-30T10:29:28.58578Z",
          "shell.execute_reply": "2025-01-30T10:29:29.291513Z"
        },
        "id": "5i4w-sAyxnhd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('/kaggle/input/semantic-similarity/keras/default/1/semantic_TRNSFRM.keras')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T10:31:36.712119Z",
          "iopub.execute_input": "2025-01-30T10:31:36.712427Z",
          "iopub.status.idle": "2025-01-30T10:31:39.422758Z",
          "shell.execute_reply.started": "2025-01-30T10:31:36.712404Z",
          "shell.execute_reply": "2025-01-30T10:31:39.421695Z"
        },
        "id": "YBq1MF2wxnhd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate([x1_test[0], x1_test[1]], y_test, batch_size=128)\n",
        "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T10:31:40.225893Z",
          "iopub.execute_input": "2025-01-30T10:31:40.226287Z",
          "iopub.status.idle": "2025-01-30T10:31:56.039638Z",
          "shell.execute_reply.started": "2025-01-30T10:31:40.226259Z",
          "shell.execute_reply": "2025-01-30T10:31:56.038728Z"
        },
        "id": "r605MHYUxnhj",
        "outputId": "3cfc8861-b9ef-4098-f0a2-87b642693239"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 30ms/step - accuracy: 0.7348 - loss: 0.5227\nTest Loss: 0.5244, Test Accuracy: 0.7334\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict([x1_test[0], x1_test[1]])\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T10:32:01.129258Z",
          "iopub.execute_input": "2025-01-30T10:32:01.129591Z",
          "iopub.status.idle": "2025-01-30T10:32:18.601332Z",
          "shell.execute_reply.started": "2025-01-30T10:32:01.129563Z",
          "shell.execute_reply": "2025-01-30T10:32:18.600281Z"
        },
        "id": "jWCQKHjJxnhj",
        "outputId": "d2b30704-4151-449a-bc73-4dd306ece2cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\u001b[1m1867/1867\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Assuming all preprocessing functions, embedding_matrix, and model creation are already done\n",
        "\n",
        "def preprocess_sentences(sentence1, sentence2, tokenizer, max_len):\n",
        "    \"\"\"\n",
        "    Preprocess sentences: Tokenize and pad to max_len.\n",
        "    \"\"\"\n",
        "    # Tokenizing the input sentences\n",
        "    sequences1 = tokenizer.texts_to_sequences([sentence1])\n",
        "    sequences2 = tokenizer.texts_to_sequences([sentence2])\n",
        "\n",
        "    # Padding sequences\n",
        "    padded_seq1 = pad_sequences(sequences1, maxlen=max_len, padding=\"post\")\n",
        "    padded_seq2 = pad_sequences(sequences2, maxlen=max_len, padding=\"post\")\n",
        "\n",
        "    return padded_seq1, padded_seq2\n",
        "\n",
        "def predict_semantics(sentence1, sentence2, tokenizer, model, max_len):\n",
        "    \"\"\"\n",
        "    Predicts whether the two input sentences are semantically the same or not.\n",
        "    \"\"\"\n",
        "    # Check if sentence length exceeds max_len\n",
        "    if len(sentence1.split()) > max_len or len(sentence2.split()) > max_len:\n",
        "        return \"Sentence is too long.\"\n",
        "\n",
        "    # Preprocess sentences\n",
        "    padded_seq1, padded_seq2 = preprocess_sentences(sentence1, sentence2, tokenizer, max_len)\n",
        "\n",
        "    # Predict with the model\n",
        "    prediction = model.predict([padded_seq1, padded_seq2])\n",
        "\n",
        "    # Convert prediction to \"same\" or \"different\"\n",
        "    if prediction >= 0.5:\n",
        "        return \"Semantically Same\"\n",
        "    else:\n",
        "        return \"Semantically Different\"\n",
        "\n",
        "# Assuming the tokenizer, embedding_matrix, and model are already defined and trained\n",
        "# Example usage:\n",
        "\n",
        "sentence1 = \"Can I get a job?\"\n",
        "sentence2 = \"Will I be employed?\"\n",
        "\n",
        "# Predict\n",
        "result = predict_semantics(sentence1, sentence2, tokenizer, model, max_len)\n",
        "print(result)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T10:33:02.254083Z",
          "iopub.execute_input": "2025-01-30T10:33:02.254512Z",
          "iopub.status.idle": "2025-01-30T10:33:02.340498Z",
          "shell.execute_reply.started": "2025-01-30T10:33:02.254479Z",
          "shell.execute_reply": "2025-01-30T10:33:02.339537Z"
        },
        "id": "JyvbqmYZxnhj",
        "outputId": "99586042-fab4-47f0-fe98-3c9b89a4fd7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\nSemantically Same\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}